{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Graphics Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Import data handling libraries\n",
    "import datetime as dt\n",
    "from pandas.core import datetools\n",
    "\n",
    "def helloWorld():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "def loadAndCleanData(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data.fillna(0)\n",
    "    #print(data)\n",
    "    return data\n",
    "\n",
    "def computeProbability(feature, bin, data):\n",
    "    # Count the number of datapoints in the bin\n",
    "    count = 0.0\n",
    "\n",
    "    for i,datapoint in data.iterrows():\n",
    "        # See if the data is in the right bin\n",
    "        if datapoint[feature] >= bin[0] and datapoint[feature] < bin[1]:\n",
    "            count += 1\n",
    "\n",
    "    # Count the total number of datapoints\n",
    "    totalData = len(data)\n",
    "\n",
    "    # Divide the number of people in the bin by the total number of people\n",
    "    probability = count / totalData\n",
    "\n",
    "    # Return the result\n",
    "    return probability\n",
    "\n",
    "def computeConfidenceInterval(data):\n",
    "      # Confidence intervals\n",
    "        npArray = 1.0 * np.array(data)\n",
    "        stdErr = scipy.stats.sem(npArray)\n",
    "        n = len(data)\n",
    "        return stdErr * scipy.stats.t.ppf((1+.95)/2.0, n - 1)\n",
    "\n",
    "def getEffectSize(d1,d2):\n",
    "    m1 = d1.mean()\n",
    "    m2 = d2.mean()\n",
    "    s1 = d1.std()\n",
    "    s2 = d2.std()\n",
    "\n",
    "    return (m1 - m2) / math.sqrt((math.pow(s1, 3) + math.pow(s2, 3)) / 2.0)\n",
    "\n",
    "def runTTest(d1,d2):\n",
    "    return scipy.stats.ttest_ind(d1,d2)\n",
    "\n",
    "# pip install statsmodels\n",
    "# vars is a string with our independent and dependent variables\n",
    "# \" dvs ~ ivs\"\n",
    "def runANOVA(dataframe, vars):\n",
    "    model = ols(vars, data=dataframe).fit()\n",
    "    aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "    return aov_table\n",
    "\n",
    "# Plot a timeline of my data\n",
    "def plotTimeline(data, time_col, val_col):\n",
    "    data.plot.line(x=time_col, y=val_col)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Plot a timeline of my data broken down by each category (cat_col)\n",
    "def plotMultipleTimelines(data, time_col, val_col, cat_col):\n",
    "    plt.style.use('ggplot')\n",
    "    data.plot.line(x=time_col, y=[val_col, cat_col], figsize = (10,7))\n",
    "    #data.plot(x=time_col, y=[val_col,cat_col], kind=\"line\")\n",
    "    plt.show()      \n",
    "    \n",
    "    \n",
    "# Run a linear regression over the data. Models an equation\n",
    "# as y = mx + b and returns the list [m, b].\n",
    "def runTemporalLinearRegression(data, x, y):\n",
    "    # Format our data for sklean by reshaping from columns to np arrays\n",
    "    x_col = data[x].map(dt.datetime.toordinal).values.reshape(-1,1)\n",
    "    y_col = data[y].values.reshape(-1, 1)\n",
    "\n",
    "    # Run the regression using an sklearn regression object\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(x_col, y_col)\n",
    "\n",
    "    # Compute the R2 score and print it. Good scores are close to 1\n",
    "    y_hat = regr.predict(x_col)\n",
    "    fitScore = r2_score(y_col, y_hat)\n",
    "    print(\"Linear Regression Fit: \" + str(fitScore))\n",
    "\n",
    "    # Plot linear regression against data. This will let us visually judge whether\n",
    "    # or not our model is any good. With small data, a high R2 doesn't always mean\n",
    "    # a good model: we can use our intuition as well.\n",
    "    #plt.scatter(data[x], y_col, color='lightblue')\n",
    "    #plt.plot(data[x], y_hat, color='red', linewidth=2)\n",
    "    #plt.show()\n",
    "\n",
    "    # y = mx + b\n",
    "    # Return m and b\n",
    "    return [regr.coef_[0][0], regr.intercept_[0]]\n",
    "\n",
    "def logistic(x, x0, m, b):\n",
    "    y = 1.0 / (1.0 + np.exp(-m*(x - x0) + b))\n",
    "    return (y)\n",
    "\n",
    "def runTemporalLogisticRegression(data, x, y):\n",
    "    x_col = data[x].map(dt.datetime.toordinal)\n",
    "    y_col = data[y]\n",
    "\n",
    "    #giving curve fit to start with\n",
    "    p0 = [np.media(x_col), 1, min(y_col)]\n",
    "    paras, pcov = curve_fit(logistic, x_col, y_col, p0)\n",
    "\n",
    "    #show fit\n",
    "    plt.scatter(data[x], y_col, color = 'lightblue')\n",
    "    plt.plot(data[x], logistic(x_col, params[0], params[1], params[2], color='red', linewidth=2))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def mergeData(data1, data2, column):\n",
    "    data = []\n",
    "    for i in data2[column]:\n",
    "        data.append(i)\n",
    "    data1[column] = data\n",
    "    return data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
